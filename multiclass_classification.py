# -*- coding: utf-8 -*-
"""multiclass_classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pe19kRUi4m58-VTmOFrYXmIdOPV3kElm

Задача многоклассовой классификации текстов на русском языке. Необходимо выполнить поставленную задачу с применением свёрточных и рекуррентных моделей нейронных сетей.
Предстоит работать с отрывками текстов классической отечественной литературы, задача определения авторства. Здесь необходимо обрезать датасет, оставив в нём только топ-5 наиболее часто встречающихся писателей из тренировочной выборки.

## Imports
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import os
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from google.colab import drive
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, Bidirectional, Dense, Dropout, GlobalMaxPooling1D, GlobalAveragePooling1D, BatchNormalization, LayerNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

np.random.seed(42)
tf.random.set_seed(42)

drive.mount('/content/drive')

"""## EDA + PREPROCESSING"""

train_data = pd.read_csv('/content/drive/My Drive/4 курс/train_data.csv')
val_data = pd.read_csv('/content/drive/My Drive/4 курс/val_data.csv')
test_data = pd.read_csv('/content/drive/My Drive/4 курс/test_data.csv')

train_data.head()

test_data.head()

# приведение столбцов к единому формату
train_data = train_data[['writer', 'book', 'text']]
val_data = val_data[['writer', 'book', 'text']]
test_data = test_data[['writer', 'book', 'text']]

train_data.info()

"""*Данные хорошо структурированы: без пропущенных значений.*"""

train_data.duplicated().any()

"""*Дубликатов нет*"""

plt.figure(figsize=(10, 5))
sns.countplot(y=train_data['writer'], order=train_data['writer'].value_counts().index)
plt.title("Распределение авторов в обучающей выборке")
plt.show()

"""*График показывает распределение авторов в обучающей выборке. Больше всего текстов принадлежит Достоевскому, за ним следуют Fray и Сергеев-Ценский.*"""

import matplotlib.pyplot as plt
import seaborn as sns

train_data['text_len'] = train_data['text'].apply(lambda x: len(x.split()))
test_data['text_len'] = test_data['text'].apply(lambda x: len(x.split()))

train_filtered = train_data[train_data['text_len'] <= 2000]
test_filtered = test_data[test_data['text_len'] <= 2000]

plt.figure(figsize=(10, 4))
plt.hist(train_filtered['text_len'], bins=30, alpha=0.7, label='Train', edgecolor='black')
plt.hist(test_filtered['text_len'], bins=30, alpha=0.7, label='Test', edgecolor='black')
plt.legend(fontsize=12)
plt.title('Распределение длины текстов', fontsize=16)
plt.xlabel('кол-во слов', fontsize=14)
plt.ylabel('Частота', fontsize=14)
plt.show()

"""*Основная масса текстов находится в диапазоне 300–350 слов. Длина текстов в train и test наборах схожа, что хорошо для обучения модели. Train содержит больше данных, но оба набора следуют похожему распределению. Нет значительных выбросов, но встречаются тексты с длиной до 450 слов.*"""

top_5_authors = train_data['writer'].value_counts().index[:5]
train_data = train_data[train_data['writer'].isin(top_5_authors)]
val_data = val_data[val_data['writer'].isin(top_5_authors)]
test_data = test_data[test_data['writer'].isin(top_5_authors)]

sns.countplot(data=train_data, x='writer', palette='viridis')
plt.title('Распределение классов')
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.show()

"""*Достоевский имеет наибольшее количество текстов, за ним следуют Fray, Сергеев-Ценский, Солженицын и Казанцев. Распределение авторов неравномерное, может повлиять на баланс модели, поэтому уровняем.*"""

from sklearn.utils import resample

min_samples = train_data['writer'].value_counts().min()
balanced_train = train_data.groupby('writer', group_keys=False).apply(lambda x: x.sample(min_samples, random_state=42))

sns.countplot(data=balanced_train, x='writer', palette='viridis')
plt.title('Распределение классов')
plt.xlabel('Класс')
plt.ylabel('Количество')
plt.show()

balanced_train['writer'].value_counts()

label_encoder = LabelEncoder()
train_labels = label_encoder.fit_transform(balanced_train['writer'])
val_labels = label_encoder.transform(val_data['writer'])
test_labels = label_encoder.transform(test_data['writer'])

max_words = 20000
max_length = 500

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(balanced_train['text'])

def preprocess_texts(texts):
    sequences = tokenizer.texts_to_sequences(texts)
    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')
    return padded_sequences

train_sequences = preprocess_texts(balanced_train['text'])
val_sequences = preprocess_texts(val_data['text'])
test_sequences = preprocess_texts(test_data['text'])

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

"""## CNN"""

cnn_model = Sequential([
    Embedding(input_dim=20000, output_dim=128, input_length=max_length),
    SpatialDropout1D(0.3),
    BatchNormalization(),
    Conv1D(filters=32, kernel_size=5, activation='relu', kernel_regularizer=l2(0.002)),
    Dropout(0.4),
    MaxPooling1D(pool_size=2),
    GlobalAveragePooling1D(),
    Dense(16, activation='relu', kernel_regularizer=l2(0.002)),
    Dropout(0.5),
    Dense(5, activation='softmax')
])

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.0003,
    decay_steps=1000,
    decay_rate=0.9
)
optimizer = Adam(learning_rate=lr_schedule)
cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

history_cnn = cnn_model.fit(train_padded, train_labels, validation_data=(val_padded, val_labels), epochs=10, batch_size=32, callbacks=[early_stopping])

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history_cnn.history['loss'], label='Training Loss')
plt.plot(history_cnn.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_cnn.history['accuracy'], label='Training Accuracy')
plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

"""**Вывод по результатам обучения**

*1. Обучающая выборка начинается с 1.5980 , затем падает до 0.2892 (эпоха 10). Это указывает на хорошее обучение модели, так как потери стабильно уменьшаются. Нет резкого увеличения, что означает отсутствие явного переобучения.*

*То есть, потери на обучающей и валидационной выборках уменьшаются, что подтверждает устойчивый прогресс без переобучения.*

*2. Обучающая точность стартует с 33.9% и достигает 90.8% . Модель быстро обучается и выходит на высокие показатели. Валидационная точность начинается с 63.0% и растет до 91.3%. Близка к обучающей, что говорит о хорошем обобщении модели. Модель достигает высокой точности (~91%) и хорошо обобщает знания на валидационной выборке.*

*Таким образом, обучение успешное – модель уверенно улучшает точность и снижает потери; отсутствие переобучения – валидационные метрики не ухудшаются; точность ~91% – хороший результат для многоклассовой классификации текстов.*
"""

cnn_model.summary()

"""*Модель сбалансирована: 7.7M параметров — средний размер для NLP.Нет лишних необучаемых параметров.*"""

from sklearn.metrics import classification_report, confusion_matrix

def evaluate_model(model, test_padded, test_labels, model_name):
    y_pred = np.argmax(model.predict(test_padded), axis=1)
    print(f"\n=== {model_name} ===")
    print(classification_report(test_labels, y_pred))

evaluate_model(cnn_model, test_padded, test_labels, "CNN Model")

"""*Модель показывает высокую точность (91%), но есть дисбаланс в предсказаниях некоторых классов. Класс 1 (recall = 0.66) предсказывается хуже остальных, что указывает на сложность его распознавания. Классы 0, 3 и 4 определяются хорошо (recall > 0.95), что говорит о высокой уверенности модели в этих категориях. F1-score > 0.87 для большинства классов — модель в целом сбалансирована.*"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


y_pred = np.argmax(cnn_model.predict(test_padded), axis=1)
cm = confusion_matrix(test_labels, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Предсказанный класс')
plt.ylabel('Истинный класс')
plt.title('Confusion Matrix - CNN Model')
plt.show()

"""*Модель хорошо распознает Dostoevsky, Kazantsev и Solzhenitsin. Fray имеет наибольшее количество ошибок, часто путается с Kazantsev и Solzhenitsin. Sergeev-Thsenskiy иногда ошибочно классифицируется как Kazantsev, но в целом стабилен.*

## LSTM
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

rnn_model = Sequential([
    Embedding(input_dim=20000, output_dim=128, input_length=200),
    Bidirectional(LSTM(64, dropout=0.5, recurrent_dropout=0.3, kernel_regularizer=l2(0.002))),
    BatchNormalization(),
    Dense(32, activation='relu', kernel_regularizer=l2(0.002)),
    Dropout(0.5),
    Dense(5, activation='softmax')
])

rnn_optimizer = Adam(learning_rate=0.0005)
rnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=rnn_optimizer, metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history_rnn = rnn_model.fit(train_padded, train_labels,
                            validation_data=(val_padded, val_labels),
                            epochs=10, batch_size=32, callbacks=[early_stopping])

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history_lstm.history['loss'], label='Training Loss')
plt.plot(history_lstm.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_lstm.history['accuracy'], label='Training Accuracy')
plt.plot(history_lstm.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

"""**Вывод по результатам обучения**

1. **train_loss** продолжает снижаться, значит модель хорошо обучается.
2. **val_loss** после 4-й эпохи стабилизируется, но не снижается значительно. **train_accuracy** выше 96%, но **val_accuracy** стабилизировалась на ~73%.
3. Разрыв между **train_accuracy** и **val_accuracy** означает, что модель запомнила тренировочные данные, но не так круто обобщает.
"""

lstm_model.summary()

def evaluate_model(model, test_padded, test_labels, model_name):
    y_pred = np.argmax(model.predict(test_padded), axis=1)
    print(f"\n=== {model_name} ===")
    print(classification_report(test_labels, y_pred))

evaluate_model(lstm_model, test_padded, test_labels, "RNN Model")

"""**Средняя точность** = 72%, **средняя полнота** = 71%.
**F1-score** для класса Fray = 61%, что говорит о проблемах с его предсказанием.
Класс 3 (Sergeev-Thsenskiy) показывает хороший баланс (**F1-score** = 74%).
RNN работает стабильно, но хуже, чем CNN (CNN ~91%, RNN ~72%).

"""

y_pred = np.argmax(lstm_model.predict(test_padded), axis=1)
cm = confusion_matrix(test_labels, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Предсказанный класс')
plt.ylabel('Истинный класс')
plt.title('Confusion Matrix - RNN Model')
plt.show()

"""*Dostoevsky, Sergeev-Thsenskiy классифицируются хорошлучше всего. Fray и Kazantsev сильно путаются друг с другом. Видно, что модель лучше предсказывает одни классы, но хуже другие, хотя основные классы предсказываются неплохо.*

**` Общий вывод:`** RNN справляется неплохо, но уступает CNN.
"""